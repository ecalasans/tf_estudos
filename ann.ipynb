{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ANN Technologies Using TensorFlow 2 #\n",
    "\n",
    "The canonical way to present data to a TensorFlow ANN, as recommended\n",
    "by Google, is via a data pipeline composed of a `tf.data.Dataset` object and a\n",
    "tf.data.Iterator method. A `tf.data.Dataset` object consists of a sequence of\n",
    "elements in which each element contains one or more tensor objects. The\n",
    "`tf.data.Iterator` is a method used to loop over a dataset so that successive\n",
    "individual elements in it may be accessed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Usando `NumPy` arrays com datasets##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.int64>\n",
      "<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f9b28297a20>\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "num_items = 11\n",
    "num_list1 = np.arange(num_items)\n",
    "num_list2 = np.arange(num_items, num_items**2)\n",
    "\n",
    "# Criando o dataset\n",
    "num_list1_dataset = tf.data.Dataset.from_tensor_slices(num_list1)\n",
    "\n",
    "print(num_list1_dataset)\n",
    "\n",
    "# Criando o iterador\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(num_list1_dataset)\n",
    "print(iterator)\n",
    "\n",
    "# Utilizando o iterador para mostrar o conteúdo do dataset\n",
    "for item in num_list1_dataset:\n",
    "    num = iterator.get_next().numpy()\n",
    "    print(num)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 12 13]\n",
      "[14 15 16]\n",
      "[17 18 19]\n",
      "[20 21 22]\n",
      "[23 24 25]\n",
      "[26 27 28]\n",
      "[29 30 31]\n",
      "[32 33 34]\n",
      "[35 36 37]\n",
      "[38 39 40]\n",
      "[41 42 43]\n",
      "[44 45 46]\n",
      "[47 48 49]\n",
      "[50 51 52]\n",
      "[53 54 55]\n",
      "[56 57 58]\n",
      "[59 60 61]\n",
      "[62 63 64]\n",
      "[65 66 67]\n",
      "[68 69 70]\n",
      "[71 72 73]\n",
      "[74 75 76]\n",
      "[77 78 79]\n",
      "[80 81 82]\n",
      "[83 84 85]\n",
      "[86 87 88]\n",
      "[89 90 91]\n",
      "[92 93 94]\n",
      "[95 96 97]\n",
      "[ 98  99 100]\n",
      "[101 102 103]\n",
      "[104 105 106]\n",
      "[107 108 109]\n",
      "[110 111 112]\n",
      "[113 114 115]\n",
      "[116 117 118]\n",
      "[119 120]\n"
     ]
    }
   ],
   "source": [
    "# Também é possível acessar os dados em batches\n",
    "num_list2_dataset = tf.data.Dataset.from_tensor_slices(num_list2)\\\n",
    "    .batch(3, drop_remainder=False)\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(num_list2_dataset)\n",
    "\n",
    "for item in num_list2_dataset:\n",
    "    num = iterator.get_next().numpy()\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a função `zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dataset1 = [1,2,3,4,5]\n",
    "dataset2 = ['a', 'e', 'i', 'o', 'u']\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(dataset1)\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(dataset2)\n",
    "\n",
    "zipped_datasets = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(zipped_datasets)\n",
    "\n",
    "for item in zipped_datasets:\n",
    "    num = iterator.get_next()[0].numpy()\n",
    "    print(num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se concatenar 2 datasets com `concatenate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "ds1 = tf.data.Dataset.from_tensor_slices([1,2,3,5,7,11,13,17])\n",
    "ds2 = tf.data.Dataset.from_tensor_slices([19,23,29,31,37,41])\n",
    "ds3 = ds1.concatenate(ds2)\n",
    "\n",
    "for i in ds3:\n",
    "    print(i.numpy())\n",
    "\n",
    "# Agora usando o iterator\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(ds3)\n",
    "for i in range(14):\n",
    "    num = iterator.get_next().numpy()\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for e in range(epochs):\n",
    "    for item in ds3:\n",
    "        print(item.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando arquivos CSV##\n",
    "`tf.data.experimental.CsvDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "1\n",
      "b\n",
      "2\n",
      "c\n",
      "3\n",
      "d\n",
      "4\n",
      "e\n",
      "5\n",
      "f\n",
      "6\n",
      "g\n",
      "7\n",
      "h\n",
      "8\n",
      "i\n",
      "9\n",
      "j\n",
      "10\n",
      "k\n",
      "11\n",
      "l\n",
      "12\n",
      "m\n",
      "13\n",
      "n\n",
      "14\n",
      "o\n",
      "15\n",
      "p\n",
      "16\n",
      "q\n",
      "17\n",
      "r\n",
      "18\n",
      "s\n",
      "19\n",
      "t\n",
      "20\n",
      "u\n",
      "21\n",
      "v\n",
      "22\n",
      "w\n",
      "23\n",
      "x\n",
      "24\n",
      "y\n",
      "25\n",
      "z\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "filename = ['./Pasta1.csv']\n",
    "record_defaults = [tf.string, tf.int32]\n",
    "dataset_csv = tf.data.experimental.CsvDataset(\n",
    "    filename,\n",
    "    record_defaults,\n",
    "    header=True,\n",
    "    select_cols=[0,1]\n",
    ")\n",
    "\n",
    "for item in dataset_csv:\n",
    "    print(item[0].numpy().decode('UTF-8'))\n",
    "    print(item[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding ###\n",
    "Quando um tensor é construído por labels tendo 1 para o valor correspondente.\n",
    "Por exemplo, para codificar o 5 com 10 dígitos temos:\n",
    "\n",
    "0  1  2  3  4  5  6  7  8  9 10\n",
    "\n",
    "0  0  0  0  0  1  0  0  0  0  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y = 5\n",
    "y_train_ohe = tf.one_hot(y, depth=10).numpy()\n",
    "print(y_train_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11 12 13]\n",
      "[14 15 16]\n",
      "[17 18 19]\n",
      "[20 21 22]\n",
      "[23 24 25]\n",
      "[26 27 28]\n",
      "[29 30 31]\n",
      "[32 33 34]\n",
      "[35 36 37]\n",
      "[38 39 40]\n",
      "[41 42 43]\n",
      "[44 45 46]\n",
      "[47 48 49]\n",
      "[50 51 52]\n",
      "[53 54 55]\n",
      "[56 57 58]\n",
      "[59 60 61]\n",
      "[62 63 64]\n",
      "[65 66 67]\n",
      "[68 69 70]\n",
      "[71 72 73]\n",
      "[74 75 76]\n",
      "[77 78 79]\n",
      "[80 81 82]\n",
      "[83 84 85]\n",
      "[86 87 88]\n",
      "[89 90 91]\n",
      "[92 93 94]\n",
      "[95 96 97]\n",
      "[ 98  99 100]\n",
      "[101 102 103]\n",
      "[104 105 106]\n",
      "[107 108 109]\n",
      "[110 111 112]\n",
      "[113 114 115]\n",
      "[116 117 118]\n",
      "[119 120]\n"
     ]
    }
   ],
   "source": [
    "y = 5\n",
    "y_train_ohe = tf.one_hot(y, depth=10).numpy()\n",
    "print(y_train_ohe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando a função `zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "dataset1 = [1,2,3,4,5]\n",
    "dataset2 = ['a', 'e', 'i', 'o', 'u']\n",
    "dataset1 = tf.data.Dataset.from_tensor_slices(dataset1)\n",
    "dataset2 = tf.data.Dataset.from_tensor_slices(dataset2)\n",
    "\n",
    "zipped_datasets = tf.data.Dataset.zip((dataset1, dataset2))\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(zipped_datasets)\n",
    "\n",
    "for item in zipped_datasets:\n",
    "    num = iterator.get_next()[0].numpy()\n",
    "    print(num)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se concatenar 2 datasets com `concatenate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "ds1 = tf.data.Dataset.from_tensor_slices([1,2,3,5,7,11,13,17])\n",
    "ds2 = tf.data.Dataset.from_tensor_slices([19,23,29,31,37,41])\n",
    "ds3 = ds1.concatenate(ds2)\n",
    "\n",
    "for i in ds3:\n",
    "    print(i.numpy())\n",
    "\n",
    "# Agora usando o iterator\n",
    "iterator = tf.compat.v1.data.make_one_shot_iterator(ds3)\n",
    "for i in range(14):\n",
    "    num = iterator.get_next().numpy()\n",
    "    print(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outro exemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "7\n",
      "11\n",
      "13\n",
      "17\n",
      "19\n",
      "23\n",
      "29\n",
      "31\n",
      "37\n",
      "41\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "for e in range(epochs):\n",
    "    for item in ds3:\n",
    "        print(item.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando arquivos CSV##\n",
    "`tf.data.experimental.CsvDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n",
      "c\n",
      "d\n",
      "e\n",
      "f\n",
      "g\n",
      "h\n",
      "i\n",
      "j\n",
      "k\n",
      "l\n",
      "m\n",
      "n\n",
      "o\n",
      "p\n",
      "q\n",
      "r\n",
      "s\n",
      "t\n",
      "u\n",
      "v\n",
      "w\n",
      "x\n",
      "y\n",
      "z\n"
     ]
    }
   ],
   "source": [
    "filename = ['./Pasta1.csv']\n",
    "record_defaults = [tf.string, tf.int32]\n",
    "dataset_csv = tf.data.experimental.CsvDataset(\n",
    "    filename,\n",
    "    record_defaults,\n",
    "    header=True,\n",
    "    select_cols=[0,1]\n",
    ")\n",
    "\n",
    "for item in dataset_csv:\n",
    "    print(item[0].numpy().decode('UTF-8'))\n",
    "    print(item[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot Encoding ###\n",
    "Quando um tensor é construído por labels tendo 1 para o valor correspondente.\n",
    "Por exemplo, para codificar o 5 com 10 dígitos temos:\n",
    "\n",
    "0  1  2  3  4  5  6  7  8  9 10\n",
    "\n",
    "0  0  0  0  0  1  0  0  0  0  0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "y = 5\n",
    "y_train_ohe = tf.one_hot(y, depth=10).numpy()\n",
    "print(y_train_ohe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Layers ###\n",
    "\n",
    "* Dense layers - todos os neurônios da camada anterior estão conectados a\n",
    "todos da camada seguinte: `tf.keras.layers.Dense(n=<numero de saidas>)`\n",
    "\n",
    "* Convolutional layers - os neurônios são organizados em malhas(*patches*)\n",
    "através do uso de um **filtro**, geralmente quadrado, que é passado na camada,\n",
    "numa operação chamada *convolução*(multiplicação e soma com o filtro):  `tf.keras.layers.Conv2D(filters,\n",
    "kernel_size, strides=1, padding='valid')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Calculando gradientes ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(7.0, shape=(), dtype=float32)\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "w1 = tf.Variable(2.0)\n",
    "\n",
    "def weightedSum(x1):\n",
    "    return w1 * x1\n",
    "\n",
    "with tf.GradientTape() as tape: #tf.GradientTape so pode ser chamada uma vez\n",
    "    sum = weightedSum(7.)\n",
    "    \n",
    "    [w1_grad] = tape.gradient(sum, [w1])\n",
    "    \n",
    "print(w1_grad)\n",
    "print(w1_grad.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Para chamar `tf.GradientTape` temos que passar o parâmetro\n",
    "`persistent=True`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0 6.0 5.0\n"
     ]
    }
   ],
   "source": [
    "w1, w2, w3 = tf.Variable(2.0), tf.Variable(3.0), tf.Variable(5.0)\n",
    "\n",
    "def weighted_sum(x1,x2,x3):\n",
    "    return w1*x1 + w2*x2 + w3*x3\n",
    "\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    sum = weighted_sum(7.,6.,5.)\n",
    "    \n",
    "[w1_grad] = tape.gradient(sum, [w1])\n",
    "[w2_grad] = tape.gradient(sum, [w2])\n",
    "[w3_grad] = tape.gradient(sum, [w3])\n",
    "\n",
    "print(w1_grad.numpy(), w2_grad.numpy(), w3_grad.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}